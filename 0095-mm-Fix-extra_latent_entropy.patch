From 54ca9a59810fc49075267545828e2031d92fca5c Mon Sep 17 00:00:00 2001
From: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
Date: Tue, 7 May 2019 11:46:21 +0200
Subject: [PATCH 095/103] mm: Fix extra_latent_entropy

Commit a9cd410a3d29 ("mm/page_alloc.c: memory hotplug: free pages as
higher order") changed `static void __init __free_pages_boot_core()`
into `void __free_pages_core()`, causing the following section mismatch
warning at compile time:

    WARNING: vmlinux.o(.text+0x180fe4): Section mismatch in reference from the function __free_pages_core() to the variable .meminit.data:extra_latent_entropy
    The function __free_pages_core() references the variable __meminitdata extra_latent_entropy.
    This is often because __free_pages_core lacks a __meminitdata annotation or the annotation of extra_latent_entropy is wrong.

This commit is an attempt at fixing this issue. I'm not sure it's OK as
we are accessing pages that are still managed by the memblock allocator.
The prefetching part is not an issue as it only affects struct pages.

Signed-off-by: Thibaut Sautereau <thibaut.sautereau@ssi.gouv.fr>
[levente@leventepolyak.net: most of core MM initialization moved to mm/mm_init.c]
Signed-off-by: Levente Polyak <levente@leventepolyak.net>
[nicolas.bouchinet@ssi.gouv.fr: MAX_ORDER has been renamed to MAX_PAGE_ORDER (see 5e0a760b44417f7ca)]
Signed-off-by: Nicolas Bouchinet <nicolas.bouchinet@ssi.gouv.fr>
---
 mm/internal.h   |  3 +++
 mm/mm_init.c    |  3 +++
 mm/page_alloc.c | 34 +++++++++++++++++++---------------
 3 files changed, 25 insertions(+), 15 deletions(-)

diff --git a/mm/internal.h b/mm/internal.h
index a963f67d3452..55c45115117e 100644
--- a/mm/internal.h
+++ b/mm/internal.h
@@ -657,6 +657,9 @@ static inline struct folio *page_rmappable_folio(struct page *page)
 	return folio;
 }
 
+extern void __init __gather_extra_latent_entropy(struct page *page,
+						 unsigned int nr_pages);
+
 static inline void prep_compound_head(struct page *page, unsigned int order)
 {
 	struct folio *folio = (struct folio *)page;
diff --git a/mm/mm_init.c b/mm/mm_init.c
index 51960079875b..638242a45134 100644
--- a/mm/mm_init.c
+++ b/mm/mm_init.c
@@ -1934,6 +1934,7 @@ static void __init deferred_free_pages(unsigned long pfn,
 	if (nr_pages == MAX_ORDER_NR_PAGES && IS_MAX_ORDER_ALIGNED(pfn)) {
 		for (i = 0; i < nr_pages; i += pageblock_nr_pages)
 			set_pageblock_migratetype(page + i, MIGRATE_MOVABLE);
+		__gather_extra_latent_entropy(page, 1 << MAX_PAGE_ORDER);
 		__free_pages_core(page, MAX_PAGE_ORDER, MEMINIT_EARLY);
 		return;
 	}
@@ -1944,6 +1945,7 @@ static void __init deferred_free_pages(unsigned long pfn,
 	for (i = 0; i < nr_pages; i++, page++, pfn++) {
 		if (pageblock_aligned(pfn))
 			set_pageblock_migratetype(page, MIGRATE_MOVABLE);
+		__gather_extra_latent_entropy(page, 1);
 		__free_pages_core(page, 0, MEMINIT_EARLY);
 	}
 }
@@ -2462,6 +2464,7 @@ void __init memblock_free_pages(struct page *page, unsigned long pfn,
 
 	/* pages were reserved and not allocated */
 	clear_page_tag_ref(page);
+	__gather_extra_latent_entropy(page, 1 << order);
 	__free_pages_core(page, order, MEMINIT_EARLY);
 }
 
diff --git a/mm/page_alloc.c b/mm/page_alloc.c
index 4099b07fdf85..c1612151cf66 100644
--- a/mm/page_alloc.c
+++ b/mm/page_alloc.c
@@ -1235,6 +1235,25 @@ static void __free_pages_ok(struct page *page, unsigned int order,
 	__count_vm_events(PGFREE, 1 << order);
 }
 
+void __init __gather_extra_latent_entropy(struct page *page,
+					  unsigned int nr_pages)
+{
+	if (extra_latent_entropy && !PageHighMem(page) && page_to_pfn(page) < 0x100000) {
+		unsigned long hash = 0;
+		size_t index, end = PAGE_SIZE * nr_pages / sizeof hash;
+		const unsigned long *data = lowmem_page_address(page);
+
+		for (index = 0; index < end; index++)
+			hash ^= hash + data[index];
+#ifdef CONFIG_GCC_PLUGIN_LATENT_ENTROPY
+		latent_entropy ^= hash;
+		add_device_randomness((const void *)&latent_entropy, sizeof(latent_entropy));
+#else
+		add_device_randomness((const void *)&hash, sizeof(hash));
+#endif
+	}
+}
+
 void __meminit __free_pages_core(struct page *page, unsigned int order,
 		enum meminit_context context)
 {
@@ -1271,21 +1290,6 @@ void __meminit __free_pages_core(struct page *page, unsigned int order,
 			set_page_count(p, 0);
 		}
 
-		if (extra_latent_entropy && !PageHighMem(page) && page_to_pfn(page) < 0x100000) {
-			unsigned long hash = 0;
-			size_t index, end = PAGE_SIZE * nr_pages / sizeof hash;
-			const unsigned long *data = lowmem_page_address(page);
-
-			for (index = 0; index < end; index++)
-				hash ^= hash + data[index];
-#ifdef CONFIG_GCC_PLUGIN_LATENT_ENTROPY
-			latent_entropy ^= hash;
-			add_device_randomness((const void *)&latent_entropy, sizeof(latent_entropy));
-#else
-			add_device_randomness((const void *)&hash, sizeof(hash));
-#endif
-		}
-
 		/* memblock adjusts totalram_pages() manually. */
 		atomic_long_add(nr_pages, &page_zone(page)->managed_pages);
 	}
-- 
2.47.0

